{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence\n",
      "C:\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Iterable\n",
      "C:\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스태킹에 사용될 머신러닝 알고리즘 클래스를 생성했다 \n",
    "\n",
    "\n",
    "개별 모델은 KNN, 랜덤 포레스트, 결정트리, 에이다 부스트이다. \n",
    "\n",
    "최종 모델은 로지스틱 회귀이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "#스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
    "lr_final = LogisticRegression(C = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도 : 0.9211\n",
      "랜덤 포레스트 정확도 : 0.9649\n",
      "결정 트리 정확도 : 0.9123\n",
      "에이다부스트 정확도 : 0.9561\n"
     ]
    }
   ],
   "source": [
    "#학습된 개별 모델들이 각자 반환하는 예측 데이터 세트를 생성하고 개별 모델의 정확도 측정 \n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도 : {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도 : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('결정 트리 정확도 : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도 : {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 알고리즘으로부터 예측된 예측 값을 칼럼 레벨로 옆으로 붙여 피처 값으로 만들어, \n",
    "\n",
    "최종 모델인 로지스틱 회귀에서 학습 데이터로 사용 \n",
    "\n",
    "\n",
    "반환된 예측 데이터 세트는 1차원 형태의 ndarray이므로 먼저 반환된 예측 결과를 행 형태로 붙인 뒤, \n",
    "\n",
    "넘파이의 transpose() 를 이용해 행과열 위치를 바꾼 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "#transpose를 이용해 행과 열의 위치 교환. 칼럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 데이터로 생성된 데이터 세트를 기반으로 최종 메타 모델인 로지스틱 회귀를 학습, \n",
    "\n",
    "예측 정확도 측정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도 : 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(pred, y_test)\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 세트 기반의 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수.\n",
    "def get_stacking_base_estimators(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    #지정된 n_folds 값으로 KFold 생성.\n",
    "    kf = KFold(n_splits= n_folds, shuffle=False, random_state = 0)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, 'model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/ 예측할 폴드 데이터 세트 추출\n",
    "        print('\\t 폴드 세트 : ', folder_counter, '시작')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr, y_tr)\n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장.\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    #폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred , axis = 1).reshape(-1, 1)\n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터 \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier model 시작\n",
      "\t 폴드 세트 :  0 시작\n",
      "\t 폴드 세트 :  1 시작\n",
      "\t 폴드 세트 :  2 시작\n",
      "\t 폴드 세트 :  3 시작\n",
      "\t 폴드 세트 :  4 시작\n",
      "\t 폴드 세트 :  5 시작\n",
      "\t 폴드 세트 :  6 시작\n",
      "RandomForestClassifier model 시작\n",
      "\t 폴드 세트 :  0 시작\n",
      "\t 폴드 세트 :  1 시작\n",
      "\t 폴드 세트 :  2 시작\n",
      "\t 폴드 세트 :  3 시작\n",
      "\t 폴드 세트 :  4 시작\n",
      "\t 폴드 세트 :  5 시작\n",
      "\t 폴드 세트 :  6 시작\n",
      "DecisionTreeClassifier model 시작\n",
      "\t 폴드 세트 :  0 시작\n",
      "\t 폴드 세트 :  1 시작\n",
      "\t 폴드 세트 :  2 시작\n",
      "\t 폴드 세트 :  3 시작\n",
      "\t 폴드 세트 :  4 시작\n",
      "\t 폴드 세트 :  5 시작\n",
      "\t 폴드 세트 :  6 시작\n",
      "AdaBoostClassifier model 시작\n",
      "\t 폴드 세트 :  0 시작\n",
      "\t 폴드 세트 :  1 시작\n",
      "\t 폴드 세트 :  2 시작\n",
      "\t 폴드 세트 :  3 시작\n",
      "\t 폴드 세트 :  4 시작\n",
      "\t 폴드 세트 :  5 시작\n",
      "\t 폴드 세트 :  6 시작\n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_estimators(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_estimators(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_estimators(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_estimators(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape :  (455, 30) 원본 테스트 피처 Shape :  (114, 30)\n",
      "스태킹 학습 피처 데이터 Shape :  (455, 4) 스태킹 테스트 피처 데이터 Shape (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis = 1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis = 1)\n",
    "print('원본 학습 피처 데이터 Shape : ', X_train.shape, '원본 테스트 피처 Shape : ', X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape : ', Stack_final_X_train.shape,\n",
    "     '스태킹 테스트 피처 데이터 Shape', Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도 : 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
